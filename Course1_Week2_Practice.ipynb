{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d5de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66aa4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f957f416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 3s 0us/step ETA\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the traning and test split of the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78e0dd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL:9\n",
      "\n",
      "Image Pixel Array:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  82 187  26   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 179 240 237 255 240 139  83  64  43  60  54   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0  58 239 222 234 238 246 252 254 255 248 255 187   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   3   0   0 194 239 226 237 235 232 230 234 234 233 249 171   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   0   0  10 255 226 242 239 238 239 240 239 242 238 248 192   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 172 245 229 240 241 240 241 243 243 241 227 250 209   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   6   5   0  62 255 230 236 239 241 242 241 242 242 238 238 242 253   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   3   0   0 255 235 228 244 241 241 244 243 243 244 243 239 235 255  22   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 246 228 220 245 243 237 241 242 242 242 243 239 237 235 253 106   0]\n",
      " [  0   0   3   4   4   2   1   0   0  18 243 228 231 241 243 237 238 242 241 240 240 240 235 237 236 246 234   0]\n",
      " [  1   0   0   0   0   0   0   0  22 255 238 227 238 239 237 241 241 237 236 238 239 239 239 239 239 237 255   0]\n",
      " [  0   0   0   0   0  25  83 168 255 225 225 235 228 230 227 225 227 231 232 237 240 236 238 239 239 235 251  62]\n",
      " [  0 165 225 220 224 255 255 233 229 223 227 228 231 232 235 237 233 230 228 230 233 232 235 233 234 235 255  58]\n",
      " [ 52 251 221 226 227 225 225 225 226 226 225 227 231 229 232 239 245 250 251 252 254 254 252 254 252 235 255   0]\n",
      " [ 31 208 230 233 233 237 236 236 241 235 241 247 251 254 242 236 233 227 219 202 193 189 186 181 171 165 190  42]\n",
      " [ 77 199 172 188 199 202 218 219 220 229 234 222 213 209 207 210 203 184 152 171 165 162 162 167 168 157 192  78]\n",
      " [  0  45 101 140 159 174 182 186 185 188 195 197 188 175 133  70  19   0   0 209 231 218 222 224 227 217 229  93]\n",
      " [  0   0   0   0   0   0   2  24  37  45  32  18  11   0   0   0   0   0   0  72  51  53  37  34  29  31   5   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23aa6ae45b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You can put between 0 to 59999 here\n",
    "index = 42\n",
    "\n",
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "# Print the label and image\n",
    "print(f'LABEL:{training_labels[index]}')\n",
    "print(f'\\nImage Pixel Array:\\n{training_images[index]}')\n",
    "\n",
    "#Visualise the image\n",
    "plt.imshow(training_images[index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c8304a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the pixel values of the train and test images\n",
    "\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "637837d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the classification model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6f5758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function: [[1. 3. 4. 2.]]\n",
      "output of softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 1.0\n",
      "class with highest probability: 2\n"
     ]
    }
   ],
   "source": [
    "# Declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function: {inputs.numpy()}')\n",
    "\n",
    "# Feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax function: {outputs.numpy()}')\n",
    "\n",
    "# Get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# Get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with highest probability: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb731994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4944 - accuracy: 0.8264\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3746 - accuracy: 0.8630\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3382 - accuracy: 0.8766\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3136 - accuracy: 0.8849\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2962 - accuracy: 0.8901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23abec1cf40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26f45f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 996us/step - loss: 0.3507 - accuracy: 0.8722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3506826162338257, 0.8722000122070312]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on unseen data\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e411b4",
   "metadata": {},
   "source": [
    "## Exercise-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dd5ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46717537e-06 1.23753505e-08 9.87698172e-08 1.40652983e-08 5.13228031e-07 1.17005967e-02 7.81000210e-07 1.30209252e-02 7.74355431e-06 9.75267828e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83da49bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4adadb",
   "metadata": {},
   "source": [
    "## Exercise-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27e91547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 4s 0us/step\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1850\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0746\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0493\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0339\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0257\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0689\n",
      "[2.0889804e-08 1.9140871e-09 2.0391806e-08 7.1270347e-07 1.8249475e-13 2.1177225e-10 7.1199063e-13 9.9999917e-01 2.8278432e-10 1.2687084e-07]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu), # Try experimenting with this layer\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "174a5d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.6793\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3344\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2810\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2678\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2315\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2762\n",
      "[0.0000000e+00 1.3543957e-24 9.5442636e-21 2.3954163e-17 6.2713377e-25 5.8124262e-23 0.0000000e+00 1.0000000e+00 1.2385366e-33 3.7183772e-27]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "model.evaluate(test_images, test_labels)\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e46cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
